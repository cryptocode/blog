<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Cache Me If You Can | cryptocode</title>
<meta name="keywords" content="">
<meta name="description" content="How come adding a single keyword to a struct in Zig give a 56% performance increase, with far less variability? As it turns out, densely packed data structures and field reorderings can cause significant performance issues in multithreaded programs due to false sharing.">
<meta name="author" content="">
<link rel="canonical" href="https://cryptocode.github.io/blog/docs/falsesharing/">
<link crossorigin="anonymous" href="/blog/assets/css/stylesheet.174413eb633337f9ef5559b1971a230b72b3f88ecd559baf9f55129e7ed6c011.css" integrity="sha256-F0QT62MzN/nvVVmxlxojC3Kz&#43;I7NVZuvn1USnn7WwBE=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/blog/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://cryptocode.github.io/blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://cryptocode.github.io/blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://cryptocode.github.io/blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://cryptocode.github.io/blog/apple-touch-icon.png">
<link rel="mask-icon" href="https://cryptocode.github.io/blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Cache Me If You Can" />
<meta property="og:description" content="How come adding a single keyword to a struct in Zig give a 56% performance increase, with far less variability? As it turns out, densely packed data structures and field reorderings can cause significant performance issues in multithreaded programs due to false sharing." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cryptocode.github.io/blog/docs/falsesharing/" /><meta property="article:section" content="docs" />
<meta property="article:published_time" content="2023-07-08T18:45:37+02:00" />
<meta property="article:modified_time" content="2023-07-08T18:45:37+02:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Cache Me If You Can"/>
<meta name="twitter:description" content="How come adding a single keyword to a struct in Zig give a 56% performance increase, with far less variability? As it turns out, densely packed data structures and field reorderings can cause significant performance issues in multithreaded programs due to false sharing."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Docs",
      "item": "https://cryptocode.github.io/blog/docs/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Cache Me If You Can",
      "item": "https://cryptocode.github.io/blog/docs/falsesharing/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Cache Me If You Can",
  "name": "Cache Me If You Can",
  "description": "How come adding a single keyword to a struct in Zig give a 56% performance increase, with far less variability? As it turns out, densely packed data structures and field reorderings can cause significant performance issues in multithreaded programs due to false sharing.\n",
  "keywords": [
    
  ],
  "articleBody": "How come adding a single keyword to a struct in Zig give a 56% performance increase, with far less variability? As it turns out, densely packed data structures and field reorderings can cause significant performance issues in multithreaded programs due to false sharing.\nWhile packing data closely together can be very beneficial due to cache locality, false sharing must be taking into account when designing optimal data layouts for multithreaded programs.\nCache lines False sharing occurs when the data layout is at odds with the memory access pattern, namely multiple threads managing separate data that happens to fall on the same cache line.\nA cache line is the smallest unit of transfer between Lx caches and main memory, and thus also the unit of synchronization of coherence protocols such as MESI.\nCache line invalidation is very expensive, and may additionally cause issues for applications that are sensitive to performance variability. The actual impact depends on a thread’s affinity to core socket and hyperthreads, scheduling, and the number of threads.\nA cache line is typically 64 bytes, but this can vary between CPU architectures. Tools such as lstopo is useful to determine the cache line size and the cache hierachy on your CPU.\nA little Zig surprise Take a look at this struct:\nconst Queue = struct { head_index: u64 = 0, padding: [128]u8 = undefined, tail_index: u64 = 0, }; Now imagine you have two threads updating head_index and tail_index respectively.\nChanging the struct to the following makes the program run 30% faster on my Intel Core i9, and with an order of magnitude lower standard deviation:\nconst Queue = extern struct { head_index: u64 = 0, padding: [128]u8 = undefined, tail_index: u64 = 0, }; The difference? The extern keyword. This tells the compiler to adhere to the C ABI, which means the compiler will not reorder the fields.\nNote that we can not use a packed struct in this example as the padding type is not supported (In Zig, packed structs are just fancy integers)\nFor regular structs, Zig may reorder the fields to minimize padding, which is a good thing in general.\nHowever, by enforcing the ordering, the indended reason for padding causes head_index and tail_index to fall on different cache lines, and thus false sharing is avoided: The two threads can update their respective fields without invalidating each other’s cache lines.\nTo reduce the chance of false sharing, we must force a suitable field ordering, add padding fields or set alignment on specific fields.\nThe code The benchmark below demonstrates the issue. It is a simple queue implementation that is used by two threads, one that pushes items onto the queue, and one that pops items off the queue.\nOf course, a benchmark is designed to demonstrate a specific issue, and the numbers below are not representative of a real world application. However, if false sharing occurs on the hot path of your application, the performance impact can be significant.\nconst std = @import(\"std\"); // Remove \"extern\" to observe false sharing const Data = extern struct { head_index: u64 align(64) = 0, padding: [128]u8 = undefined, tail_index: u64 = 0, }; fn updateHeadIndex(data: anytype) anyerror!void { for (0..2000000000) |i| { data.head_index += 1; std.math.doNotOptimizeAway(i); } } fn updateTailIndex(data: anytype) anyerror!void { for (0..2000000000) |i| { data.tail_index += 1; std.math.doNotOptimizeAway(i); } } pub fn main() anyerror!void { var data: Data = .{}; var head_thread = try std.Thread.spawn(.{}, updateHeadIndex, .{\u0026data}); var tail_thread = try std.Thread.spawn(.{}, updateTailIndex, .{\u0026data}); head_thread.join(); tail_thread.join(); } The doNotOptimizeAway(i) call boils down to asm volatile (\"\" :: [i] \"r\" (i),); on my system, which is a barrier that prevents the compiler from simply optimizing away the loop (which wouldn’t make for a useful benchmark)\nzig build-exe -OReleaseFast falsesharing.zig hyperfine --export-json results-with-extern.json ./falsesharing Do the same without the extern keyword (rename the json output filename in the hyperfine command), and observe the difference.\nThe numbers The following tables shows the benchmark summary and 10 timings for the case where false sharing does not occur, and 10 timings for the case where false sharing does occur.\nWhile a larger number of samples were taken to verify the effect, the numbers below are representative.\nNot only is the average time for the false sharing case significantly worse, the standard deviation is also an order of magnitude higher.\nTimings are measured in seconds.\nNo false sharing False sharing mean 3.0299017825599996 4.738531733004999 stddev 0.011379971724662449 0.13044659161376454 median 3.02725268766 4.7289631684049995 min 3.01537040366 4.582206681904999 max 3.0460710066599996 5.081537872905 The actual runs:\nNo false sharing False sharing 3.0440456 4.5822066 3.0200773 4.7326414 3.0460710 5.0815378 3.0245974 4.6807162 3.0153704 4.7508973 3.0307415 4.7335685 3.0283079 4.6781897 3.0449196 4.7252849 3.0261973 4.7423249 3.0186892 4.6779495 Hyperthreading adds a twist The timings above are with hyperthreading disabled. With hyperthreading enabled, the timings for the false sharing case are much more variable, but still consistently worse than the no false sharing case.\nOn Linux, you might want to consider using pthread_setaffinity_np to pin threads to physical cores.\nThis is currently not support on macOS. However, you can disable hyperthreading by entering safe mode and entering these commands in the terminal:\nnvram boot-args=\"cwae=2\" nvram SMTDisable=%01 After rebooting, System Information (click Apple icon in the menu bar while holding Alt) should report `Hyper-Threading Technology: Disabled\"\nResetting the NVRAM will re-enable hyperthreading.\nCache topology The cache topology on my machine (with Hyperthreading disabled) is as follows, using lstopo from the hwloc package:\nlstopo - -v --no-io Package L#0 NUMANode L#0 (P#0 local=33554432KB total=33554432KB) L3Cache L#0 (size=16384KB linesize=64) L2Cache L#0 (size=256KB linesize=64) L1dCache L#0 (size=32KB linesize=64) L1iCache L#0 (size=32KB linesize=64) Core L#0 (P#0) PU L#0 (P#0) L2Cache L#1 (size=256KB linesize=64) L1dCache L#1 (size=32KB linesize=64) L1iCache L#1 (size=32KB linesize=64) Core L#1 (P#1) PU L#1 (P#1) L2Cache L#2 (size=256KB linesize=64) L1dCache L#2 (size=32KB linesize=64) L1iCache L#2 (size=32KB linesize=64) Core L#2 (P#2) PU L#2 (P#2) L2Cache L#3 (size=256KB linesize=64) L1dCache L#3 (size=32KB linesize=64) L1iCache L#3 (size=32KB linesize=64) Core L#3 (P#3) PU L#3 (P#3) L2Cache L#4 (size=256KB linesize=64) L1dCache L#4 (size=32KB linesize=64) L1iCache L#4 (size=32KB linesize=64) Core L#4 (P#4) PU L#4 (P#4) L2Cache L#5 (size=256KB linesize=64) L1dCache L#5 (size=32KB linesize=64) L1iCache L#5 (size=32KB linesize=64) Core L#5 (P#5) PU L#5 (P#5) L2Cache L#6 (size=256KB linesize=64) L1dCache L#6 (size=32KB linesize=64) L1iCache L#6 (size=32KB linesize=64) Core L#6 (P#6) PU L#6 (P#6) L2Cache L#7 (size=256KB linesize=64) L1dCache L#7 (size=32KB linesize=64) L1iCache L#7 (size=32KB linesize=64) Core L#7 (P#7) PU L#7 (P#7) ",
  "wordCount" : "1053",
  "inLanguage": "en",
  "datePublished": "2023-07-08T18:45:37+02:00",
  "dateModified": "2023-07-08T18:45:37+02:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://cryptocode.github.io/blog/docs/falsesharing/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "cryptocode",
    "logo": {
      "@type": "ImageObject",
      "url": "https://cryptocode.github.io/blog/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://cryptocode.github.io/blog/" accesskey="h" title="cryptocode (Alt + H)">cryptocode</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Cache Me If You Can
    </h1>
    <div class="post-meta"><span title='2023-07-08 18:45:37 +0200 +0200'>July 8, 2023</span>

</div>
  </header> 
  <div class="post-content"><p>How come adding a single keyword to a struct in Zig give a 56% performance increase, with far less variability? As it turns out, densely packed data structures and field reorderings can cause significant performance issues in multithreaded programs due to <em>false sharing</em>.</p>
<p>While packing data closely together can be very beneficial due to cache locality, false sharing must be taking into account when designing optimal data layouts for multithreaded programs.</p>
<h3 id="cache-lines">Cache lines<a hidden class="anchor" aria-hidden="true" href="#cache-lines">#</a></h3>
<p>False sharing occurs when the data layout is at odds with the memory access pattern, namely multiple threads managing separate data that happens to fall on the same <em>cache line</em>.</p>
<p>A cache line is the smallest unit of transfer between Lx caches and main memory, and thus also the unit of synchronization of coherence protocols such as MESI.</p>
<p>Cache line invalidation is very expensive, and may additionally cause issues for applications that are sensitive to performance variability. The actual impact depends on a thread&rsquo;s affinity to core socket and hyperthreads, scheduling, and the number of threads.</p>
<p>A cache line is typically 64 bytes, but this can vary between CPU architectures. Tools such as <code>lstopo</code> is useful to determine the cache line size and the cache hierachy on your CPU.</p>
<h3 id="a-little-zig-surprise">A little Zig surprise<a hidden class="anchor" aria-hidden="true" href="#a-little-zig-surprise">#</a></h3>
<p>Take a look at this struct:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-zig" data-lang="zig"><span style="display:flex;"><span><span style="color:#66d9ef">const</span> Queue <span style="color:#f92672">=</span> <span style="color:#66d9ef">struct</span>  {
</span></span><span style="display:flex;"><span>    head_index<span style="color:#f92672">:</span> <span style="color:#66d9ef">u64</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    padding<span style="color:#f92672">:</span> [<span style="color:#ae81ff">128</span>]<span style="color:#66d9ef">u8</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">undefined</span>,
</span></span><span style="display:flex;"><span>    tail_index<span style="color:#f92672">:</span> <span style="color:#66d9ef">u64</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>Now imagine you have two threads updating <code>head_index</code> and <code>tail_index</code> respectively.</p>
<p>Changing the struct to the following makes the program run 30% faster on my Intel Core i9, and with an <em>order of magnitude</em> lower standard deviation:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-zig" data-lang="zig"><span style="display:flex;"><span><span style="color:#66d9ef">const</span> Queue <span style="color:#f92672">=</span> <span style="color:#66d9ef">extern</span> <span style="color:#66d9ef">struct</span>  {
</span></span><span style="display:flex;"><span>    head_index<span style="color:#f92672">:</span> <span style="color:#66d9ef">u64</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    padding<span style="color:#f92672">:</span> [<span style="color:#ae81ff">128</span>]<span style="color:#66d9ef">u8</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">undefined</span>,
</span></span><span style="display:flex;"><span>    tail_index<span style="color:#f92672">:</span> <span style="color:#66d9ef">u64</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>The difference? The <code>extern</code> keyword. This tells the compiler to adhere to the C ABI, which means the compiler will <em>not</em> reorder the fields.</p>
<p><em>Note that we can not use a</em> <code>packed struct</code> <em>in this example as the padding type is not supported (In Zig, packed structs are just fancy integers)</em></p>
<p>For regular structs, Zig may reorder the fields to <em>minimize padding</em>, which is a good thing in general.</p>
<p>However, by enforcing the ordering, the indended reason for padding causes <code>head_index</code> and <code>tail_index</code> to fall on different cache lines, and thus false sharing is avoided: The two threads can update their respective fields without invalidating each other&rsquo;s cache lines.</p>
<p>To reduce the chance of false sharing, we must force a suitable field ordering, add padding fields or set alignment on specific fields.</p>
<h3 id="the-code">The code<a hidden class="anchor" aria-hidden="true" href="#the-code">#</a></h3>
<p>The benchmark below demonstrates the issue. It is a simple queue implementation that is used by two threads, one that pushes items onto the queue, and one that pops items off the queue.</p>
<p>Of course, a benchmark is designed to demonstrate a specific issue, and the numbers below are not representative of a real world application. However, if false sharing occurs on the hot path of your application, the performance impact can be significant.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-zig" data-lang="zig"><span style="display:flex;"><span><span style="color:#66d9ef">const</span> std <span style="color:#f92672">=</span> @import(<span style="color:#e6db74">&#34;std&#34;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Remove &#34;extern&#34; to observe false sharing
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">const</span> Data <span style="color:#f92672">=</span> <span style="color:#66d9ef">extern</span> <span style="color:#66d9ef">struct</span>  {
</span></span><span style="display:flex;"><span>    head_index<span style="color:#f92672">:</span> <span style="color:#66d9ef">u64</span> <span style="color:#66d9ef">align</span>(<span style="color:#ae81ff">64</span>) <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    padding<span style="color:#f92672">:</span> [<span style="color:#ae81ff">128</span>]<span style="color:#66d9ef">u8</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">undefined</span>,
</span></span><span style="display:flex;"><span>    tail_index<span style="color:#f92672">:</span> <span style="color:#66d9ef">u64</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> updateHeadIndex(data<span style="color:#f92672">:</span> anytype) <span style="color:#66d9ef">anyerror</span><span style="color:#f92672">!</span><span style="color:#66d9ef">void</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> (<span style="color:#ae81ff">0</span>..<span style="color:#ae81ff">2000000000</span>) <span style="color:#f92672">|</span>i<span style="color:#f92672">|</span> {
</span></span><span style="display:flex;"><span>        data.head_index <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>;
</span></span><span style="display:flex;"><span>        std.math.doNotOptimizeAway(i);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> updateTailIndex(data<span style="color:#f92672">:</span> anytype) <span style="color:#66d9ef">anyerror</span><span style="color:#f92672">!</span><span style="color:#66d9ef">void</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> (<span style="color:#ae81ff">0</span>..<span style="color:#ae81ff">2000000000</span>) <span style="color:#f92672">|</span>i<span style="color:#f92672">|</span> {
</span></span><span style="display:flex;"><span>        data.tail_index <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>;
</span></span><span style="display:flex;"><span>        std.math.doNotOptimizeAway(i);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">pub</span> <span style="color:#66d9ef">fn</span> main() <span style="color:#66d9ef">anyerror</span><span style="color:#f92672">!</span><span style="color:#66d9ef">void</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">var</span> data<span style="color:#f92672">:</span> Data <span style="color:#f92672">=</span> .{};
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">var</span> head_thread <span style="color:#f92672">=</span> <span style="color:#66d9ef">try</span> std.Thread.spawn(.{}, updateHeadIndex, .{<span style="color:#f92672">&amp;</span>data});
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">var</span> tail_thread <span style="color:#f92672">=</span> <span style="color:#66d9ef">try</span> std.Thread.spawn(.{}, updateTailIndex, .{<span style="color:#f92672">&amp;</span>data});
</span></span><span style="display:flex;"><span>    head_thread.join();
</span></span><span style="display:flex;"><span>    tail_thread.join();
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The <code>doNotOptimizeAway(i)</code> call boils down to <code>asm volatile (&quot;&quot; :: [i] &quot;r&quot; (i),);</code> on my system, which is a barrier that prevents the compiler from simply optimizing away the loop (which wouldn&rsquo;t make for a useful benchmark)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>zig build-exe -OReleaseFast falsesharing.zig
</span></span><span style="display:flex;"><span>hyperfine --export-json results-with-extern.json ./falsesharing   
</span></span></code></pre></div><p>Do the same without the <code>extern</code> keyword (rename the json output filename in the hyperfine command), and observe the difference.</p>
<h3 id="the-numbers">The numbers<a hidden class="anchor" aria-hidden="true" href="#the-numbers">#</a></h3>
<p>The following tables shows the benchmark summary and 10 timings for the case where false sharing does not occur, and 10 timings for the case where false sharing does occur.</p>
<p>While a larger number of samples were taken to verify the effect, the numbers below are representative.</p>
<p>Not only is the average time for the false sharing case significantly worse, the standard deviation is also an order of magnitude higher.</p>
<p>Timings are measured in seconds.</p>
<table>
<thead>
<tr>
<th></th>
<th>No false sharing</th>
<th>False sharing</th>
</tr>
</thead>
<tbody>
<tr>
<td>mean</td>
<td>3.0299017825599996</td>
<td>4.738531733004999</td>
</tr>
<tr>
<td>stddev</td>
<td>0.011379971724662449</td>
<td>0.13044659161376454</td>
</tr>
<tr>
<td>median</td>
<td>3.02725268766</td>
<td>4.7289631684049995</td>
</tr>
<tr>
<td>min</td>
<td>3.01537040366</td>
<td>4.582206681904999</td>
</tr>
<tr>
<td>max</td>
<td>3.0460710066599996</td>
<td>5.081537872905</td>
</tr>
</tbody>
</table>
<p>The actual runs:</p>
<table>
<thead>
<tr>
<th>No false sharing</th>
<th>False sharing</th>
</tr>
</thead>
<tbody>
<tr>
<td>3.0440456</td>
<td>4.5822066</td>
</tr>
<tr>
<td>3.0200773</td>
<td>4.7326414</td>
</tr>
<tr>
<td>3.0460710</td>
<td>5.0815378</td>
</tr>
<tr>
<td>3.0245974</td>
<td>4.6807162</td>
</tr>
<tr>
<td>3.0153704</td>
<td>4.7508973</td>
</tr>
<tr>
<td>3.0307415</td>
<td>4.7335685</td>
</tr>
<tr>
<td>3.0283079</td>
<td>4.6781897</td>
</tr>
<tr>
<td>3.0449196</td>
<td>4.7252849</td>
</tr>
<tr>
<td>3.0261973</td>
<td>4.7423249</td>
</tr>
<tr>
<td>3.0186892</td>
<td>4.6779495</td>
</tr>
</tbody>
</table>
<h3 id="hyperthreading-adds-a-twist">Hyperthreading adds a twist<a hidden class="anchor" aria-hidden="true" href="#hyperthreading-adds-a-twist">#</a></h3>
<p>The timings above are with hyperthreading disabled. With hyperthreading enabled, the timings for the false sharing case are much more variable, but still consistently worse than the no false sharing case.</p>
<p>On Linux, you might want to consider using <code>pthread_setaffinity_np</code> to pin threads to physical cores.</p>
<p>This is currently not support on macOS. However, you can disable hyperthreading by entering safe mode and entering these commands in the terminal:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nvram boot-args<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;cwae=2&#34;</span>
</span></span><span style="display:flex;"><span>nvram SMTDisable<span style="color:#f92672">=</span>%01
</span></span></code></pre></div><p>After rebooting, System Information (click Apple icon in the menu bar while holding Alt) should report `Hyper-Threading Technology: Disabled&quot;</p>
<p>Resetting the NVRAM will re-enable hyperthreading.</p>
<h3 id="cache-topology">Cache topology<a hidden class="anchor" aria-hidden="true" href="#cache-topology">#</a></h3>
<p>The cache topology on my machine (with Hyperthreading disabled) is as follows, using <code>lstopo</code> from the <code>hwloc</code> package:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>lstopo - -v --no-io
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  Package L#0
</span></span><span style="display:flex;"><span>    NUMANode L#0 <span style="color:#f92672">(</span>P#0 local<span style="color:#f92672">=</span>33554432KB total<span style="color:#f92672">=</span>33554432KB<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    L3Cache L#0 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>16384KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>      L2Cache L#0 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>256KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>        L1dCache L#0 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>32KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>          L1iCache L#0 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>32KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            Core L#0 <span style="color:#f92672">(</span>P#0<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>              PU L#0 <span style="color:#f92672">(</span>P#0<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>      L2Cache L#1 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>256KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>        L1dCache L#1 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>32KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>          L1iCache L#1 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>32KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            Core L#1 <span style="color:#f92672">(</span>P#1<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>              PU L#1 <span style="color:#f92672">(</span>P#1<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>      L2Cache L#2 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>256KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>        L1dCache L#2 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>32KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>          L1iCache L#2 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>32KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            Core L#2 <span style="color:#f92672">(</span>P#2<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>              PU L#2 <span style="color:#f92672">(</span>P#2<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>      L2Cache L#3 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>256KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>        L1dCache L#3 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>32KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>          L1iCache L#3 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>32KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            Core L#3 <span style="color:#f92672">(</span>P#3<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>              PU L#3 <span style="color:#f92672">(</span>P#3<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>      L2Cache L#4 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>256KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>        L1dCache L#4 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>32KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>          L1iCache L#4 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>32KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            Core L#4 <span style="color:#f92672">(</span>P#4<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>              PU L#4 <span style="color:#f92672">(</span>P#4<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>      L2Cache L#5 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>256KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>        L1dCache L#5 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>32KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>          L1iCache L#5 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>32KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            Core L#5 <span style="color:#f92672">(</span>P#5<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>              PU L#5 <span style="color:#f92672">(</span>P#5<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>      L2Cache L#6 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>256KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>        L1dCache L#6 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>32KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>          L1iCache L#6 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>32KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            Core L#6 <span style="color:#f92672">(</span>P#6<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>              PU L#6 <span style="color:#f92672">(</span>P#6<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>      L2Cache L#7 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>256KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>        L1dCache L#7 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>32KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>          L1iCache L#7 <span style="color:#f92672">(</span>size<span style="color:#f92672">=</span>32KB linesize<span style="color:#f92672">=</span>64<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>            Core L#7 <span style="color:#f92672">(</span>P#7<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>              PU L#7 <span style="color:#f92672">(</span>P#7<span style="color:#f92672">)</span>
</span></span></code></pre></div>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
     </body>

</html>
