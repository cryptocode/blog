<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Cache Me If You Can |  ~/cryptocode</title>
<meta name="keywords" content="">
<meta name="description" content="How come making a struct in Zig less densely packed can give a huge performance increase, with far less variability? This post takes a look at false sharing and how it can be caused by packed data layouts and unintended field reorderings.
While packing data closely together can be beneficial due to cache locality, false sharing must be taken into account when designing optimal data layouts for multithreaded programs.
False sharing occurs when the data layout is at odds with the memory access pattern, namely threads updating thread-specific data that happens to fall on the same cache line.">
<meta name="author" content="">
<link rel="canonical" href="https://cryptocode.github.io/blog/docs/falsesharing/">
<link crossorigin="anonymous" href="/blog/assets/css/stylesheet.31670b680bf0c33daf591b5847a304d489f83cb2bc3d2971d5f25009e51af4ca.css" integrity="sha256-MWcLaAvwwz2vWRtYR6ME1In4PLK8PSlx1fJQCeUa9Mo=" rel="preload stylesheet" as="style"><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Gentium+Plus:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
<link rel="icon" href="https://cryptocode.github.io/blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://cryptocode.github.io/blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://cryptocode.github.io/blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://cryptocode.github.io/blog/apple-touch-icon.png">
<link rel="mask-icon" href="https://cryptocode.github.io/blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="Cache Me If You Can" />
<meta property="og:description" content="How come making a struct in Zig less densely packed can give a huge performance increase, with far less variability? This post takes a look at false sharing and how it can be caused by packed data layouts and unintended field reorderings.
While packing data closely together can be beneficial due to cache locality, false sharing must be taken into account when designing optimal data layouts for multithreaded programs.
False sharing occurs when the data layout is at odds with the memory access pattern, namely threads updating thread-specific data that happens to fall on the same cache line." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cryptocode.github.io/blog/docs/falsesharing/" />
<meta property="og:image" content="https://cryptocode.github.io/blog/images/mondrian.png" />
<meta property="article:section" content="docs" />
<meta property="article:published_time" content="2023-07-09T10:00:00+02:00" />
<meta property="article:modified_time" content="2023-07-09T10:00:00+02:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://cryptocode.github.io/blog/images/mondrian.png" />
<meta name="twitter:title" content="Cache Me If You Can"/>
<meta name="twitter:description" content="How come making a struct in Zig less densely packed can give a huge performance increase, with far less variability? This post takes a look at false sharing and how it can be caused by packed data layouts and unintended field reorderings.
While packing data closely together can be beneficial due to cache locality, false sharing must be taken into account when designing optimal data layouts for multithreaded programs.
False sharing occurs when the data layout is at odds with the memory access pattern, namely threads updating thread-specific data that happens to fall on the same cache line."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Docs",
      "item": "https://cryptocode.github.io/blog/docs/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Cache Me If You Can",
      "item": "https://cryptocode.github.io/blog/docs/falsesharing/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Cache Me If You Can",
  "name": "Cache Me If You Can",
  "description": "How come making a struct in Zig less densely packed can give a huge performance increase, with far less variability? This post takes a look at false sharing and how it can be caused by packed data layouts and unintended field reorderings.\nWhile packing data closely together can be beneficial due to cache locality, false sharing must be taken into account when designing optimal data layouts for multithreaded programs.\nFalse sharing occurs when the data layout is at odds with the memory access pattern, namely threads updating thread-specific data that happens to fall on the same cache line.",
  "keywords": [
    
  ],
  "articleBody": "How come making a struct in Zig less densely packed can give a huge performance increase, with far less variability? This post takes a look at false sharing and how it can be caused by packed data layouts and unintended field reorderings.\nWhile packing data closely together can be beneficial due to cache locality, false sharing must be taken into account when designing optimal data layouts for multithreaded programs.\nFalse sharing occurs when the data layout is at odds with the memory access pattern, namely threads updating thread-specific data that happens to fall on the same cache line.\nImagine we’re writing some sort of concurrent queue where multiple threads update head- and tail indices. To avoid false sharing, we must to go from this situation:\nTo something like this:\nThread 1 only cares about head_index, while thread 2 only cares about tail_index\nBy padding the struct, we ensure that each thread has its own cache line and can thus update its field without invalidating the other thread’s cache line.\nA cache line is the smallest unit of transfer between each core’s local Lx cache and main memory, and thus also the unit of synchronization of coherence protocols such as MESI. Updating a cache line on one core will invalidate the corresponding line on all other cores’ local caches.\nCache line invalidation is expensive, and may additionally cause issues for applications that are sensitive to performance variability. The actual impact depends on a thread’s affinity to core socket and hyperthreads, scheduling, and the number of threads. Memory access not involving false sharing may also be affected due to intra-socket coherence traffic saturation.\nA cache line is typically 64 bytes, but this varies between CPU architectures. Tools such as lstopo are useful to determine the cache hierachy and line size on your CPU.\nRegular struct vs extern struct Take a look at this Zig struct:\nconst Queue = struct { head_index: u64 = 0, padding: [64]u8 = undefined, tail_index: u64 = 0, }; Now imagine you have two threads updating head_index and tail_index respectively.\nChanging the struct to the following makes my benchmark run 56% faster on an Intel Core i9, and with an order of magnitude lower standard deviation:\nconst Queue = extern struct { head_index: u64 = 0, padding: [64]u8 = undefined, tail_index: u64 = 0, }; The difference? The extern keyword. This tells the compiler to adhere to the C ABI, which means the compiler will not reorder the fields.\nFor regular structs, Zig is free to reorder the fields to minimize padding, which is a good thing in general.\nHowever, by enforcing the specified order, the padding field fulfills its intended purpose: It places head_index and tail_index on separate cache lines.\nThe code The benchmark is designed to demonstrate the issue at hand, and the results are not necessarily representative of false sharing slowdowns in a real-world application. That said, if false sharing occurs in a hot path, the impact can be significant.\nconst std = @import(\"std\"); // Remove \"extern\" or the padding to observe false sharing const Data = extern struct { head_index: u64 align(64) = 0, padding: [128]u8 = undefined, tail_index: u64 = 0, }; fn updateHeadIndex(data: anytype) anyerror!void { for (0..2000000000) |i| { data.head_index += 1; std.math.doNotOptimizeAway(i); } } fn updateTailIndex(data: anytype) anyerror!void { for (0..2000000000) |i| { data.tail_index += 1; std.math.doNotOptimizeAway(i); } } pub fn main() anyerror!void { var data: Data = .{}; var head_thread = try std.Thread.spawn(.{}, updateHeadIndex, .{\u0026data}); var tail_thread = try std.Thread.spawn(.{}, updateTailIndex, .{\u0026data}); head_thread.join(); tail_thread.join(); } The doNotOptimizeAway(i) call introduces a barrier that prevents the compiler from optimizing away the loop (which wouldn’t make for a useful benchmark)\nzig build-exe -OReleaseFast falsesharing.zig hyperfine --export-json results-with-extern.json ./falsesharing Do the same without the extern keyword (rename the json output filename in the hyperfine command), and observe the difference.\nResult Timings are measured in seconds.\nNo false sharing False sharing mean 3.0299017825599996 4.738531733004999 stddev 0.011379971724662449 0.13044659161376454 median 3.02725268766 4.7289631684049995 min 3.01537040366 4.582206681904999 max 3.0460710066599996 5.081537872905 The actual runs:\nNo false sharing False sharing 3.0440456 4.5822066 3.0200773 4.7326414 3.0460710 5.0815378 3.0245974 4.6807162 3.0153704 4.7508973 3.0307415 4.7335685 3.0283079 4.6781897 3.0449196 4.7252849 3.0261973 4.7423249 3.0186892 4.6779495 Hyperthreading adds a twist The timings above are with hyperthreading disabled. With hyperthreading enabled, the penalty for the false sharing case is sometimes less severe (depending on affinity), but average run times are still much worse than the no false sharing case. Hyperthreading also adds more variance, 0.06 vs 0.011 standard deviation.\nOn Linux, you might want to consider using pthread_setaffinity_np to pin threads to physical cores.\nThis is currently not supported on macOS. For the purposes of replicating this benchmark, you can disable hyperthreading by entering safe mode and entering these commands in the terminal:\nnvram boot-args=\"cwae=2\" nvram SMTDisable=%01 After rebooting, System Information (click Apple icon in the menu bar while holding Alt) should report `Hyper-Threading Technology: Disabled\"\nResetting the NVRAM will re-enable hyperthreading.\n",
  "wordCount" : "815",
  "inLanguage": "en",
  "image": "https://cryptocode.github.io/blog/images/mondrian.png","datePublished": "2023-07-09T10:00:00+02:00",
  "dateModified": "2023-07-09T10:00:00+02:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://cryptocode.github.io/blog/docs/falsesharing/"
  },
  "publisher": {
    "@type": "Organization",
    "name": " ~/cryptocode",
    "logo": {
      "@type": "ImageObject",
      "url": "https://cryptocode.github.io/blog/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://cryptocode.github.io/blog/" accesskey="h" title=" ~/cryptocode (Alt + H)">
                <img src="https://cryptocode.github.io/blog/images/mondrian.png" alt="" aria-label="logo"
                    height="35"> ~/cryptocode</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Cache Me If You Can
    </h1>
    <div class="post-meta"><span title='2023-07-09 10:00:00 +0200 +0200'>July 9, 2023</span>

</div>
  </header> 
  <div class="post-content"><p>How come making a struct in Zig <em>less</em> densely packed can give a huge performance increase, with far less variability? This post takes a look at false sharing and how it can be caused by packed data layouts and unintended field reorderings.</p>
<p>While packing data closely together can be beneficial due to cache locality, false sharing must be taken into account when designing optimal data layouts for multithreaded programs.</p>
<p>False sharing occurs when the data layout is at odds with the memory access pattern, namely threads updating thread-specific data that happens to fall on the same <em>cache line</em>.</p>
<p>Imagine we&rsquo;re writing some sort of concurrent queue where multiple threads update head- and tail indices. To avoid false sharing, we must to go from this situation:</p>
<p><img loading="lazy" src="/blog/images/false-sharing-bad.png" alt="Cachelines"  />
</p>
<p>To something like this:</p>
<p><img loading="lazy" src="/blog/images/false-sharing-good.png" alt="Cachelines"  />
</p>
<p>Thread 1 only cares about <em>head_index</em>, while thread 2 only cares about <em>tail_index</em></p>
<p>By padding the struct, we ensure that each thread has its own cache line and can thus update its field without invalidating the other thread&rsquo;s cache line.</p>
<p>A cache line is the smallest unit of transfer between each core&rsquo;s local Lx cache and main memory, and thus also the unit of synchronization of coherence protocols such as MESI. Updating a cache line on one core will invalidate the corresponding line on all other cores&rsquo; local caches.</p>
<p>Cache line invalidation is expensive, and may additionally cause issues for applications that are sensitive to performance variability. The actual impact depends on a thread&rsquo;s affinity to core socket and hyperthreads, scheduling, and the number of threads. Memory access not involving false sharing may also be affected due to intra-socket coherence traffic saturation.</p>
<p>A cache line is typically 64 bytes, but this varies between CPU architectures. Tools such as <code>lstopo</code> are useful to determine the cache hierachy and line size on your CPU.</p>
<h2 id="regular-struct-vs-extern-struct">Regular struct vs extern struct<a hidden class="anchor" aria-hidden="true" href="#regular-struct-vs-extern-struct">#</a></h2>
<p>Take a look at this Zig struct:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-zig" data-lang="zig"><span style="display:flex;"><span><span style="color:#66d9ef">const</span> Queue <span style="color:#f92672">=</span> <span style="color:#66d9ef">struct</span>  {
</span></span><span style="display:flex;"><span>    head_index<span style="color:#f92672">:</span> <span style="color:#66d9ef">u64</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    padding<span style="color:#f92672">:</span> [<span style="color:#ae81ff">64</span>]<span style="color:#66d9ef">u8</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">undefined</span>,
</span></span><span style="display:flex;"><span>    tail_index<span style="color:#f92672">:</span> <span style="color:#66d9ef">u64</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>Now imagine you have two threads updating <code>head_index</code> and <code>tail_index</code> respectively.</p>
<p>Changing the struct to the following makes my benchmark run 56% faster on an Intel Core i9, and with an order of magnitude lower standard deviation:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-zig" data-lang="zig"><span style="display:flex;"><span><span style="color:#66d9ef">const</span> Queue <span style="color:#f92672">=</span> <span style="color:#66d9ef">extern</span> <span style="color:#66d9ef">struct</span>  {
</span></span><span style="display:flex;"><span>    head_index<span style="color:#f92672">:</span> <span style="color:#66d9ef">u64</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    padding<span style="color:#f92672">:</span> [<span style="color:#ae81ff">64</span>]<span style="color:#66d9ef">u8</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">undefined</span>,
</span></span><span style="display:flex;"><span>    tail_index<span style="color:#f92672">:</span> <span style="color:#66d9ef">u64</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>The difference? The extern keyword. This tells the compiler to adhere to the C ABI, which means the compiler will <em>not</em> reorder the fields.</p>
<p>For regular structs, Zig is free to reorder the fields to <em>minimize padding</em>, which is a good thing in general.</p>
<p>However, by enforcing the specified order, the <em>padding</em> field fulfills its intended purpose: It places <em>head_index</em> and <em>tail_index</em> on separate cache lines.</p>
<h2 id="the-code">The code<a hidden class="anchor" aria-hidden="true" href="#the-code">#</a></h2>
<p>The benchmark is designed to demonstrate the issue at hand, and the results are not necessarily representative of false sharing slowdowns in a real-world application. That said, if false sharing occurs in a hot path, the impact can be significant.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-zig" data-lang="zig"><span style="display:flex;"><span><span style="color:#66d9ef">const</span> std <span style="color:#f92672">=</span> @import(<span style="color:#e6db74">&#34;std&#34;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Remove &#34;extern&#34; or the padding to observe false sharing
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">const</span> Data <span style="color:#f92672">=</span> <span style="color:#66d9ef">extern</span> <span style="color:#66d9ef">struct</span>  {
</span></span><span style="display:flex;"><span>    head_index<span style="color:#f92672">:</span> <span style="color:#66d9ef">u64</span> <span style="color:#66d9ef">align</span>(<span style="color:#ae81ff">64</span>) <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    padding<span style="color:#f92672">:</span> [<span style="color:#ae81ff">128</span>]<span style="color:#66d9ef">u8</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">undefined</span>,
</span></span><span style="display:flex;"><span>    tail_index<span style="color:#f92672">:</span> <span style="color:#66d9ef">u64</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> updateHeadIndex(data<span style="color:#f92672">:</span> anytype) <span style="color:#66d9ef">anyerror</span><span style="color:#f92672">!</span><span style="color:#66d9ef">void</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> (<span style="color:#ae81ff">0</span>..<span style="color:#ae81ff">2000000000</span>) <span style="color:#f92672">|</span>i<span style="color:#f92672">|</span> {
</span></span><span style="display:flex;"><span>        data.head_index <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>;
</span></span><span style="display:flex;"><span>        std.math.doNotOptimizeAway(i);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> updateTailIndex(data<span style="color:#f92672">:</span> anytype) <span style="color:#66d9ef">anyerror</span><span style="color:#f92672">!</span><span style="color:#66d9ef">void</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> (<span style="color:#ae81ff">0</span>..<span style="color:#ae81ff">2000000000</span>) <span style="color:#f92672">|</span>i<span style="color:#f92672">|</span> {
</span></span><span style="display:flex;"><span>        data.tail_index <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>;
</span></span><span style="display:flex;"><span>        std.math.doNotOptimizeAway(i);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">pub</span> <span style="color:#66d9ef">fn</span> main() <span style="color:#66d9ef">anyerror</span><span style="color:#f92672">!</span><span style="color:#66d9ef">void</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">var</span> data<span style="color:#f92672">:</span> Data <span style="color:#f92672">=</span> .{};
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">var</span> head_thread <span style="color:#f92672">=</span> <span style="color:#66d9ef">try</span> std.Thread.spawn(.{}, updateHeadIndex, .{<span style="color:#f92672">&amp;</span>data});
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">var</span> tail_thread <span style="color:#f92672">=</span> <span style="color:#66d9ef">try</span> std.Thread.spawn(.{}, updateTailIndex, .{<span style="color:#f92672">&amp;</span>data});
</span></span><span style="display:flex;"><span>    head_thread.join();
</span></span><span style="display:flex;"><span>    tail_thread.join();
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The <code>doNotOptimizeAway(i)</code> call introduces a barrier that prevents the compiler from optimizing away the loop (which wouldn&rsquo;t make for a useful benchmark)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>zig build-exe -OReleaseFast falsesharing.zig
</span></span><span style="display:flex;"><span>hyperfine --export-json results-with-extern.json ./falsesharing   
</span></span></code></pre></div><p>Do the same without the <code>extern</code> keyword (rename the json output filename in the hyperfine command), and observe the difference.</p>
<h2 id="result">Result<a hidden class="anchor" aria-hidden="true" href="#result">#</a></h2>
<p>Timings are measured in seconds.</p>
<table>
<thead>
<tr>
<th></th>
<th>No false sharing</th>
<th>False sharing</th>
</tr>
</thead>
<tbody>
<tr>
<td>mean</td>
<td>3.0299017825599996</td>
<td>4.738531733004999</td>
</tr>
<tr>
<td>stddev</td>
<td>0.011379971724662449</td>
<td>0.13044659161376454</td>
</tr>
<tr>
<td>median</td>
<td>3.02725268766</td>
<td>4.7289631684049995</td>
</tr>
<tr>
<td>min</td>
<td>3.01537040366</td>
<td>4.582206681904999</td>
</tr>
<tr>
<td>max</td>
<td>3.0460710066599996</td>
<td>5.081537872905</td>
</tr>
</tbody>
</table>
<p>The actual runs:</p>
<table>
<thead>
<tr>
<th>No false sharing</th>
<th>False sharing</th>
</tr>
</thead>
<tbody>
<tr>
<td>3.0440456</td>
<td>4.5822066</td>
</tr>
<tr>
<td>3.0200773</td>
<td>4.7326414</td>
</tr>
<tr>
<td>3.0460710</td>
<td>5.0815378</td>
</tr>
<tr>
<td>3.0245974</td>
<td>4.6807162</td>
</tr>
<tr>
<td>3.0153704</td>
<td>4.7508973</td>
</tr>
<tr>
<td>3.0307415</td>
<td>4.7335685</td>
</tr>
<tr>
<td>3.0283079</td>
<td>4.6781897</td>
</tr>
<tr>
<td>3.0449196</td>
<td>4.7252849</td>
</tr>
<tr>
<td>3.0261973</td>
<td>4.7423249</td>
</tr>
<tr>
<td>3.0186892</td>
<td>4.6779495</td>
</tr>
</tbody>
</table>
<h2 id="hyperthreading-adds-a-twist">Hyperthreading adds a twist<a hidden class="anchor" aria-hidden="true" href="#hyperthreading-adds-a-twist">#</a></h2>
<p>The timings above are with hyperthreading disabled. With hyperthreading enabled, the penalty for the false sharing case is sometimes less severe (depending on affinity), but average run times are still much worse than the no false sharing case. Hyperthreading also adds more variance, 0.06 vs 0.011 standard deviation.</p>
<p>On Linux, you might want to consider using <code>pthread_setaffinity_np</code> to pin threads to physical cores.</p>
<p>This is currently not supported on macOS. For the purposes of replicating this benchmark, you can disable hyperthreading by entering safe mode and entering these commands in the terminal:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nvram boot-args<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;cwae=2&#34;</span>
</span></span><span style="display:flex;"><span>nvram SMTDisable<span style="color:#f92672">=</span>%01
</span></span></code></pre></div><p>After rebooting, System Information (click Apple icon in the menu bar while holding Alt) should report `Hyper-Threading Technology: Disabled&quot;</p>
<p>Resetting the NVRAM will re-enable hyperthreading.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
     </body>

</html>
