<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>zig on  ~/cryptocode</title>
    <link>https://cryptocode.github.io/blog/categories/zig/</link>
    <description>Recent content in zig on  ~/cryptocode</description>
    <image>
      <title> ~/cryptocode</title>
      <url>https://cryptocode.github.io/blog/images/mondrian.png</url>
      <link>https://cryptocode.github.io/blog/images/mondrian.png</link>
    </image>
    <generator>Hugo -- 0.115.1</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 29 Jul 2023 12:01:51 +0200</lastBuildDate>
    <atom:link href="https://cryptocode.github.io/blog/categories/zig/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Embedding machine code in Zig</title>
      <link>https://cryptocode.github.io/blog/docs/machinecode/</link>
      <pubDate>Sat, 29 Jul 2023 12:01:51 +0200</pubDate>
      <guid>https://cryptocode.github.io/blog/docs/machinecode/</guid>
      <description>Linux and macOS Rosetta notes Assembling Calling from Zig A larger example with fast memcpy and syscalls Using assembly code with Zig is usually done via inline assembly, or by linking to object files produced by assemblers.
This post explores a third way: write the assembly in a separate source file, run an assembler, and then embed the resulting machine code using @embedFile
Linux and macOS Rosetta notes The code is tested on macOS, but also works with minor modifications on Linux (primarily the syscall number)</description>
    </item>
    <item>
      <title>Cache Me If You Can</title>
      <link>https://cryptocode.github.io/blog/docs/falsesharing/</link>
      <pubDate>Sun, 09 Jul 2023 10:00:00 +0200</pubDate>
      <guid>https://cryptocode.github.io/blog/docs/falsesharing/</guid>
      <description>How come making a struct in Zig less densely packed can give a huge performance increase, with far less variability? This post takes a look at false sharing and how it can be caused by packed data layouts and unintended field reorderings.
While packing data closely together can be beneficial due to cache locality, false sharing must be taken into account when designing optimal data layouts for multithreaded programs.
False sharing occurs when the data layout is at odds with the memory access pattern, namely threads updating thread-specific data that happens to fall on the same cache line.</description>
    </item>
  </channel>
</rss>
